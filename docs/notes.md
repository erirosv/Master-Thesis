# Meeting May 23 

methods to use:
- Correlation-Based Feature Selection 
- Relief-Based Feature Selection 
- Genetic Algorithm (exist)
- Information Gain
- Minimum Redundancy Maximum Relevance


extra 
- SFS (run 20 feature) best and desc
- SPFSR (exist)
	- Tuning params: M=maximum iterations, mention this. Stall-limit=25 (number of consicuet iteration where nothing happends), m=number of gradiens averaging (2), t, c,  

classifications:
- k-nearest (decide K, distance)
- SVM (what type of kernel)
- decision tree (proning)
- naive bayes 


0-20 k

Evaluation:
- number for k=5
	- 5 repeated parts for cv (that will result in 25 different accuracy values)
- t-test to compare accuracy
